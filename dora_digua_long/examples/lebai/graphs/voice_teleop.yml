nodes:
  - id: lebai-client
    build: pip install -e ../../../node-hub/lebai-client
    path: lebai-client
    inputs:
      movec:
        source: interpolation/movec
        queue_size: 1
      movej:
        source: interpolation/movej
        queue_size: 1
      claw: interpolation/claw
      stop: interpolation/stop
      save: interpolation/save
      go_to: interpolation/go_to
      record: interpolation/record
      cut: interpolation/cut
      play: interpolation/play
      teach: interpolation/teach
      end_teach: interpolation/end_teach

  - id: dora-microphone
    build: pip install dora-microphone
    path: dora-microphone
    outputs:
      - audio

  - id: dora-distil-whisper
    build: pip install dora-distil-whisper
    path: dora-distil-whisper
    inputs:
      input: dora-microphone/audio
    outputs:
      - text

  - id: voice-interpolation
    path: ../nodes/voice_interpolation.py
    inputs:
      text: dora-distil-whisper/text
    outputs:
      - text

  - id: interpolation
    path: ../nodes/interpolation.py
    inputs:
      text: dora-qwenvl-recorder/text
    outputs:
      - movec
      - movej
      - claw
      - stop
      - save
      - record
      - play
      - go_to
      - cut
      - teach
      - end_teach

  - id: camera
    build: pip install opencv-video-capture
    path: opencv-video-capture
    inputs:
      tick: dora/timer/millis/16
    outputs:
      - image
    env:
      CAPTURE_PATH: 8
      IMAGE_WIDTH: 640
      IMAGE_HEIGHT: 480

  - id: plot
    build: cargo install dora-rerun --locked
    path: dora-rerun
    inputs:
      image:
        source: camera/image
        queue_size: 1
      text_vlm: dora-qwenvl-recorder/text
    env:
      IMAGE_WIDTH: 640
      IMAGE_HEIGHT: 480

  - id: dora-qwenvl-recorder
    build: pip install -e ../../../dora/node-hub/llama-factory-recorder
    path: llama-factory-recorder
    inputs:
      image:
        source: camera/image
        queue_size: 1
      ground_truth: voice-interpolation/text
    outputs:
      - text
    env:
      DEFAULT_QUESTION: Respond with left, right, forward, back, up or go home in order for the robotic arm to get the cup.
      LLAMA_FACTORY_ROOT_PATH: /home/peter/Documents/work/LLaMA-Factory
